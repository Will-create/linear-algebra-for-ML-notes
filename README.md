# linear-algebra-for-ML-notes
[![Linear Algebra for Machine Learning](https://img.youtube.com/vi/QCPJ0VdpM00/0.jpg)](https://www.youtube.com/watch?v=QCPJ0VdpM00)


## Introduction  

Welcome to **Linear Algebra for Machine Learning**!  

This repository contains comprehensive notes that cover everything you need to know about linear algebra as it applies to machine learning. Linear algebra is a foundational subject in ML, providing the mathematical framework for understanding concepts like vectors, matrices, transformations, and optimization.  

These notes are designed to be clear, structured, and educational, making them useful for learners at all levels. As I progress through the course, I will update this repository with well-organized explanations, formulas, and examples.  

## Basic Concepts and Notations  

To fully grasp the upcoming material, you should be familiar with the following fundamental concepts:  

### 1. **Real Numbers and Vector Spaces**  
   - Understanding the set of real numbers **ℝ**  
   - Vector spaces of different dimensions: **ℝ, ℝ², ℝ³, ... ℝⁿ**  
   - Representation of points and vectors in multi-dimensional spaces  

### 2. **Norms and Distance Measures**  
   - Definition of vector norms (e.g., Euclidean norm, Manhattan norm)  
   - Distance between two points in a given space  

### 3. **The Cartesian Coordinate System**  
   - Understanding the (x, y) plane and higher-dimensional generalizations  
   - Plotting points, vectors, and geometric interpretations  

### 4. **Basic Trigonometry**  
   - Fundamental trigonometric functions: **Sine (sin), Cosine (cos), Tangent (tan)**  
   - Reciprocal functions: **Cosecant (csc), Secant (sec), Cotangent (cot)**  

### 5. **Trigonometric Identities and Equations**  
   - Pythagorean identity:  
     \[
     \sin^2\theta + \cos^2\theta = 1
     \]  
   - Angle sum and difference identities  
   - Double-angle and half-angle formulas  

### 6. **The Pythagorean Theorem**  
   - The fundamental relation in Euclidean geometry:  
     \[
     a^2 + b^2 = c^2
     \]  
   - Applications in distance calculations and vector magnitudes  

### 7. **Orthogonality and Perpendicularity in Vectors**  
   - When two vectors are perpendicular, their **dot product is zero**:  
```
\[
\mathbf{a} \cdot \mathbf{b} = 0
\] 
```
 
   - Understanding orthogonal projections in vector spaces  

These topics form the foundation of much of the work we’ll do in this course. If any of these concepts feel unfamiliar, a quick refresher will be helpful before moving forward!  
